{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rue9m27h8czB"
   },
   "source": [
    "# Introduction to Scrapy\n",
    "\n",
    "This notebook provides introduction to Scrapy, a powerful Python framework for scraping and crawling trough webpages. In general there are two approaches to scraping a page:\n",
    "\n",
    "\n",
    "*   **using CSS selectors** - CSS selectors are family of patterns used to style a webpage. As styling involves personalization, CSS selectors are useful to extract information on a particular component of a page using its \"personal characteristics\".\n",
    "*   **using XPATH** - XPATH is a family of expressions used to navigate over XML documents. The latter are very similar to HTML documents, with the main difference being hte fact that tags are defined by the user and are not built-in. As a result, XPATH is also useful to navigate overl HTML documents.\n",
    "\n",
    "The Python web scraping ecosystem is full of packages that can handle either CSS selector or XPATH based approaches. We use Scrapy, as the latter provides a simple interface to both approaches. Below is a shrot comparison of the main tools for scraping webpages with Python.\n",
    "\n",
    "\n",
    "*   [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - probably the most common library used for scraping webpages with Python. It is based on parsers which extract the content using find() methods. As a result, BeautifulSoup is easy and user friendly, but has limited support for CSS selectors and no support for XPATH expressions.  \n",
    "*   [LXML](https://lxml.de/tutorial.html) - powerful and fast library mainly used for scraping a page using XPATH expressions. It has also developed CSS selector based approach (where user provided CSS selectors that were eventually translated by lxml to XPATH expressions) which was latter formed into a stand-out library (known as [CSSselect](https://cssselect.readthedocs.io/en/latest/)).\n",
    "*   [Scrapy](https://scrapy.org/) - powerful, fast and user-friendly framework supporting both CSS selectors and XPATH expressions. Scrapy also extends traditional CSS selectors by providing additional features for easy extraction of web content. As a framework, it provides a rich functionality for supervising the crawler by setting scraping delays, obeying robots.txt file, extract data into different formats etc.\n",
    "\n",
    "In this notebook, Scrapy will be used to extract information from a website http://quotes.toscrape.com/.  The same content will be scraped using both CSS selectors and XOATH approaches. The result of the scrapnig process will be independent lists on all authors names, quotes and tags on the total website. The overall stepwise logic applied to scraping will be as follows:\n",
    "\n",
    "\n",
    "1.   **Checking whether scraping is allowed** - usually, websites develop a `robots.txt` file hosted on the root folder of their domain (in this case: http://quotes.toscrape.com/robots.txt), which shows the pages that are are Disallowed to scrape. If the file does not exist, or it shows that for User Agent: * the required pages are not Disallowed, then move to next steps.\n",
    "2.   **Getting the HTML content** - the scraping task in general is done locally. The process assumes sending a request to the webpage to get its HTML content, which can later be used for scraping. Python standard `requests` library will be used to `get()` the HTML content of the webpage.\n",
    "3.   **Converting textual content to Scrapy object** - to make Scrapy functionalities available, the resulting textual content received at point 2. will be converted to Scrapy object using the `TextResponse()` function.\n",
    "4.   **Scraping a single page** - to scrape the necessary content one needs toinspect the HTML code and learn the necessary CSS selectors or XPATH expressions for scraping. In this notebook, we will first scrape a single page to see whether our selectors or expressions are correct, and then move on. `css()` and `xpath()` functions will be used to search and find content on the page matching the input selector or expression and  `extract()` method will be used to extract the matching object's content.\n",
    "5.   **Developing a function to scrape a page** - based on the code at point 4. we will develop a functino to scrape a single page to avoid copy pasting the same code.\n",
    "6.   **Crawaling and scraping the website** - the function above will be used inside a foor or while loop to collect data from all of the pages of the website. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZA-BaOQ8d3M"
   },
   "source": [
    "## Overview of the functionality\n",
    "\n",
    "The code below provides an overall comparison of the main CSS selectors and XPATH expressions used in this notebook (more on this topic can be found on https://devhints.io/xpath). Whether `css()` or `xpath()` method is used, the extraction of content in Scrapy is the same:\n",
    "\n",
    "- extract() - extracts all the matching content\n",
    "- extract_first() - extracts the very first matching content\n",
    "- get() - same as extract_first()\n",
    "- getall() - same as extract\n",
    "\n",
    "In the all code, we will be using `extract()` to extract all the matching content.\n",
    "\n",
    "```python\n",
    "#extracting all the divisions on the page\n",
    "response.css('div').extract()\n",
    "response.xpath('//div').extract()\n",
    "\n",
    "#extracting all the divisions on the page with a particular class (example: my_class)\n",
    "response.css('div[class=\"my_div\"]').extract()\n",
    "response.xpath('//div[@class=\"my_div\"]').extract()\n",
    "\n",
    "#shortcut for the same task\n",
    "response.css('div.my_div').extract()\n",
    "response.xpath('//div.my_div').extract()\n",
    "\n",
    "#extracting all the divisions on the page with a particular id (example: my_id)\n",
    "response.css('div[id=\"my_div\"]').extract()\n",
    "response.xpath('//div[@id=\"my_div\"]').extract()\n",
    "\n",
    "#shortcut for the same task\n",
    "response.css('div#my_div').extract()\n",
    "response.xpath('//div#my_div').extract()\n",
    "\n",
    "#extracting a paragraph which is the direct child of division\n",
    "response.css('div.my_div > p.my_p').extract()\n",
    "response.xpath('//div.my_div/p.my_p').extract()\n",
    "\n",
    "#extracting a paragraph which is an indirect child of division\n",
    "response.css('div.my_div p.my_p').extract() \n",
    "response.xpath('//div.my_div//p.my_p').extract()\n",
    "\n",
    "#all the code above extracts matching HTML\n",
    "#code below shows how to extract only text from matching HTML\n",
    "response.css('div.my_div p.my_p::text').extract()\n",
    "response.xpath('//div.my_div/p.my_p/text()').extract()\n",
    "\n",
    "#to extract not the HTML content or the text, but an attribute (say href), use the following code\n",
    "response.css('div.my_div p.my_p::attr(href)').extract()\n",
    "response.xpath('//div.my_div/p.my_p/@href').extract()\n",
    "\n",
    "#if the exact class name is not known, but you know that it includes \"my\" inside, use this code\n",
    "response.css('div[class*=my]::text').extract()\n",
    "response.xpath('//div[contains(@class, \"my\")]/@text()').extract()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YObuVxJIITC_"
   },
   "source": [
    "## Part 1 - steps 1 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHghDkw8GygA"
   },
   "outputs": [],
   "source": [
    "#required libs\n",
    "import time #to make scraper sleep between requests\n",
    "import requests #to send a request and get the page\n",
    "from scrapy.http import TextResponse # to convert textual HTML content to Scrapy object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESqbflW1G_C3"
   },
   "outputs": [],
   "source": [
    "#Step 2\n",
    "url = \"http://quotes.toscrape.com/\"\n",
    "page = requests.get(url)\n",
    "\n",
    "#page.status_code\n",
    "#will show whether the page was succesfully received (200)\n",
    "#or not (basically anything else)\n",
    "\n",
    "#Step 3\n",
    "response = TextResponse(url=page.url,body=page.text,encoding='utf-8')\n",
    "#TextResponse() basically distinguishes between simple text and html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bjiEhZ4RJdqz",
    "outputId": "72a21a8a-2a9c-4c08-82f8-92a36905160b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'André Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin']\n"
     ]
    }
   ],
   "source": [
    "#code to extract all authors on a single page\n",
    "authors = response.css(\"small::text\").extract()\n",
    "#for xpath: response.xpath(\"//small/text()\").extract()\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "SMYnNPzUJdtX",
    "outputId": "3c905c1d-122a-4519-8fcd-cbf689a8c8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "#code to extract all quotes on a single page\n",
    "quotes = response.css(\"span[class='text']::text\").extract()\n",
    "#for xpath: response.xpath(\"//span[@class='text']/text()\").extract()\n",
    "print(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "nDi6WutLJdwC",
    "outputId": "a017bb37-d387-4b92-ef5b-5171c2820565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['change', 'deep-thoughts', 'thinking', 'world', 'abilities', 'choices', 'inspirational', 'life', 'live', 'miracle', 'miracles', 'aliteracy', 'books', 'classic', 'humor', 'be-yourself', 'inspirational', 'adulthood', 'success', 'value', 'life', 'love', 'edison', 'failure', 'inspirational', 'paraphrased', 'misattributed-eleanor-roosevelt', 'humor', 'obvious', 'simile', 'love', 'inspirational', 'life', 'humor', 'books', 'reading', 'friendship', 'friends', 'truth', 'simile']\n"
     ]
    }
   ],
   "source": [
    "#code to extract all tags on a single page\n",
    "tags = response.css(\"a[class='tag']::text\").extract()\n",
    "#for xpath: response.xpath(\"//a[@class='tag']/text()\").extract()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "lqizLPaMKB9n",
    "outputId": "579f6aea-ded2-49cc-fa8c-0a4702b0b8ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/tag/change/page/1/', '/tag/deep-thoughts/page/1/', '/tag/thinking/page/1/', '/tag/world/page/1/', '/tag/abilities/page/1/', '/tag/choices/page/1/', '/tag/inspirational/page/1/', '/tag/life/page/1/', '/tag/live/page/1/', '/tag/miracle/page/1/', '/tag/miracles/page/1/', '/tag/aliteracy/page/1/', '/tag/books/page/1/', '/tag/classic/page/1/', '/tag/humor/page/1/', '/tag/be-yourself/page/1/', '/tag/inspirational/page/1/', '/tag/adulthood/page/1/', '/tag/success/page/1/', '/tag/value/page/1/', '/tag/life/page/1/', '/tag/love/page/1/', '/tag/edison/page/1/', '/tag/failure/page/1/', '/tag/inspirational/page/1/', '/tag/paraphrased/page/1/', '/tag/misattributed-eleanor-roosevelt/page/1/', '/tag/humor/page/1/', '/tag/obvious/page/1/', '/tag/simile/page/1/', '/tag/love/', '/tag/inspirational/', '/tag/life/', '/tag/humor/', '/tag/books/', '/tag/reading/', '/tag/friendship/', '/tag/friends/', '/tag/truth/', '/tag/simile/']\n"
     ]
    }
   ],
   "source": [
    "#in case you want to scrape the hyperlinks behind the tags:\n",
    "tag_urls = response.css(\"a[class='tag']::attr(href)\").extract()\n",
    "#for xpath: response.xpath(\"//a[@class='tag']/@href\").extract()\n",
    "print(tag_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nReHpaqYKa_k"
   },
   "source": [
    "## Part 2 - step 5\n",
    "\n",
    "This section will use only CSS selectors for simplicity.\n",
    "One can easily develop functinos with XPATH expressions as well, jsut by changing the `\"response\"` line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EO2ZqgByKRGP"
   },
   "outputs": [],
   "source": [
    "#function for scraping author names from a single page, based on the code above\n",
    "def author_scraper(url):\n",
    "    page=requests.get(url)\n",
    "    response=TextResponse(url=page.url, body=page.text,encoding=\"utf-8\" )\n",
    "    authors=response.css(\"small::text\").extract()\n",
    "    return authors\n",
    "  \n",
    "#function for scraping quotes from a single page, based on the code above\n",
    "def quote_scraper(url):\n",
    "    page=requests.get(url)\n",
    "    response=TextResponse(url=page.url, body=page.text,encoding=\"utf-8\" )\n",
    "    quotes=response.css(\"span[class='text']::text\").extract()\n",
    "    return quotes\n",
    "  \n",
    "  \n",
    "#function for scraping tags from a single page, based on the code above\n",
    "def tag_scraper(url):\n",
    "    page=requests.get(url)\n",
    "    response=TextResponse(url=page.url, body=page.text,encoding=\"utf-8\" )\n",
    "    tags=response.css(\"a[class='tag']::text\").extract()\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FHE7gkeDK_RX"
   },
   "source": [
    "## Part 3 - step 6\n",
    "\n",
    "This step will be implemented only for authors for simplicity. One can do the same for other components just by changing the author_scraper() function to quotes_scraper() or tag_scraper() functions inside the loop.\n",
    "\n",
    "To scrape all the pages in a loop, we will basically develop all the URLs ina loop as well. For that reason we need to know the number of pages on the website. It is 10. Instead we can also use a while loop, which wil scrape unless the resulting list of authors on a given page is empty (no more authors to scrape!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "5xNDTfnUK-V5",
    "outputId": "02ebda48-79d5-47f0-85ec-8caadc528c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'André Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin', 'Marilyn Monroe', 'J.K. Rowling', 'Albert Einstein', 'Bob Marley', 'Dr. Seuss', 'Douglas Adams', 'Elie Wiesel', 'Friedrich Nietzsche', 'Mark Twain', 'Allen Saunders', 'Pablo Neruda', 'Ralph Waldo Emerson', 'Mother Teresa', 'Garrison Keillor', 'Jim Henson', 'Dr. Seuss', 'Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Bob Marley', 'Dr. Seuss', 'J.K. Rowling', 'Bob Marley', 'Mother Teresa', 'J.K. Rowling', 'Charles M. Schulz', 'William Nicholson', 'Albert Einstein', 'Jorge Luis Borges', 'George Eliot', 'George R.R. Martin', 'C.S. Lewis', 'Marilyn Monroe', 'Marilyn Monroe', 'Albert Einstein', 'Marilyn Monroe', 'Marilyn Monroe', 'Martin Luther King Jr.', 'J.K. Rowling', 'James Baldwin', 'Jane Austen', 'Eleanor Roosevelt', 'Marilyn Monroe', 'Albert Einstein', 'Haruki Murakami', 'Alexandre Dumas fils', 'Stephenie Meyer', 'Ernest Hemingway', 'Helen Keller', 'George Bernard Shaw', 'Charles Bukowski', 'Suzanne Collins', 'Suzanne Collins', 'C.S. Lewis', 'J.R.R. Tolkien', 'J.K. Rowling', 'Ernest Hemingway', 'Ralph Waldo Emerson', 'Mark Twain', 'Dr. Seuss', 'Alfred Tennyson', 'Charles Bukowski', 'Terry Pratchett', 'Dr. Seuss', 'J.D. Salinger', 'George Carlin', 'John Lennon', 'W.C. Fields', 'Ayn Rand', 'Mark Twain', 'Albert Einstein', 'Jane Austen', 'J.K. Rowling', 'Jane Austen', 'Jane Austen', 'C.S. Lewis', 'C.S. Lewis', 'Mark Twain', 'Mark Twain', 'C.S. Lewis', 'J.K. Rowling', 'Jimi Hendrix', 'J.M. Barrie', 'E.E. Cummings', 'Khaled Hosseini', 'Harper Lee', \"Madeleine L'Engle\", 'Mark Twain', 'Dr. Seuss', 'George R.R. Martin']\n"
     ]
    }
   ],
   "source": [
    "all_authors=[] #empty list to be populated will all authors afterwards\n",
    "for i in range(1,11): # as we have 10 pages\n",
    "    url = \"http://quotes.toscrape.com/page/{}/\".format(i) #we will construct current page's URL\n",
    "    current_page_authors = author_scraper(url) #scrape current page and save in a lsit\n",
    "    all_authors.extend(current_page_authors) #add the authots from this page to total lsit\n",
    "    time.sleep(2) #wait a bit before scrapnig next page\n",
    "print(all_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "P71ltaovK9Ld",
    "outputId": "1a9e3895-b595-43de-b101-ddebbf3619b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'André Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin', 'Marilyn Monroe', 'J.K. Rowling', 'Albert Einstein', 'Bob Marley', 'Dr. Seuss', 'Douglas Adams', 'Elie Wiesel', 'Friedrich Nietzsche', 'Mark Twain', 'Allen Saunders', 'Pablo Neruda', 'Ralph Waldo Emerson', 'Mother Teresa', 'Garrison Keillor', 'Jim Henson', 'Dr. Seuss', 'Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Bob Marley', 'Dr. Seuss', 'J.K. Rowling', 'Bob Marley', 'Mother Teresa', 'J.K. Rowling', 'Charles M. Schulz', 'William Nicholson', 'Albert Einstein', 'Jorge Luis Borges', 'George Eliot', 'George R.R. Martin', 'C.S. Lewis', 'Marilyn Monroe', 'Marilyn Monroe', 'Albert Einstein', 'Marilyn Monroe', 'Marilyn Monroe', 'Martin Luther King Jr.', 'J.K. Rowling', 'James Baldwin', 'Jane Austen', 'Eleanor Roosevelt', 'Marilyn Monroe', 'Albert Einstein', 'Haruki Murakami', 'Alexandre Dumas fils', 'Stephenie Meyer', 'Ernest Hemingway', 'Helen Keller', 'George Bernard Shaw', 'Charles Bukowski', 'Suzanne Collins', 'Suzanne Collins', 'C.S. Lewis', 'J.R.R. Tolkien', 'J.K. Rowling', 'Ernest Hemingway', 'Ralph Waldo Emerson', 'Mark Twain', 'Dr. Seuss', 'Alfred Tennyson', 'Charles Bukowski', 'Terry Pratchett', 'Dr. Seuss', 'J.D. Salinger', 'George Carlin', 'John Lennon', 'W.C. Fields', 'Ayn Rand', 'Mark Twain', 'Albert Einstein', 'Jane Austen', 'J.K. Rowling', 'Jane Austen', 'Jane Austen', 'C.S. Lewis', 'C.S. Lewis', 'Mark Twain', 'Mark Twain', 'C.S. Lewis', 'J.K. Rowling', 'Jimi Hendrix', 'J.M. Barrie', 'E.E. Cummings', 'Khaled Hosseini', 'Harper Lee', \"Madeleine L'Engle\", 'Mark Twain', 'Dr. Seuss', 'George R.R. Martin']\n"
     ]
    }
   ],
   "source": [
    "#while loop with predefined number of iterations\n",
    "all_authors=[]\n",
    "i=1\n",
    "while i<11:\n",
    "    url = \"http://quotes.toscrape.com/page/{}/\".format(i)\n",
    "    current_page_authors = author_scraper(url)\n",
    "    all_authors.extend(current_page_authors)\n",
    "    #time.sleep(2)\n",
    "    i=i+1\n",
    "print(all_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "GvgU5rCKMgYL",
    "outputId": "9644896b-3e74-4f72-e132-fc7316c18a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Jane Austen', 'Marilyn Monroe', 'Albert Einstein', 'André Gide', 'Thomas A. Edison', 'Eleanor Roosevelt', 'Steve Martin', 'Marilyn Monroe', 'J.K. Rowling', 'Albert Einstein', 'Bob Marley', 'Dr. Seuss', 'Douglas Adams', 'Elie Wiesel', 'Friedrich Nietzsche', 'Mark Twain', 'Allen Saunders', 'Pablo Neruda', 'Ralph Waldo Emerson', 'Mother Teresa', 'Garrison Keillor', 'Jim Henson', 'Dr. Seuss', 'Albert Einstein', 'J.K. Rowling', 'Albert Einstein', 'Bob Marley', 'Dr. Seuss', 'J.K. Rowling', 'Bob Marley', 'Mother Teresa', 'J.K. Rowling', 'Charles M. Schulz', 'William Nicholson', 'Albert Einstein', 'Jorge Luis Borges', 'George Eliot', 'George R.R. Martin', 'C.S. Lewis', 'Marilyn Monroe', 'Marilyn Monroe', 'Albert Einstein', 'Marilyn Monroe', 'Marilyn Monroe', 'Martin Luther King Jr.', 'J.K. Rowling', 'James Baldwin', 'Jane Austen', 'Eleanor Roosevelt', 'Marilyn Monroe', 'Albert Einstein', 'Haruki Murakami', 'Alexandre Dumas fils', 'Stephenie Meyer', 'Ernest Hemingway', 'Helen Keller', 'George Bernard Shaw', 'Charles Bukowski', 'Suzanne Collins', 'Suzanne Collins', 'C.S. Lewis', 'J.R.R. Tolkien', 'J.K. Rowling', 'Ernest Hemingway', 'Ralph Waldo Emerson', 'Mark Twain', 'Dr. Seuss', 'Alfred Tennyson', 'Charles Bukowski', 'Terry Pratchett', 'Dr. Seuss', 'J.D. Salinger', 'George Carlin', 'John Lennon', 'W.C. Fields', 'Ayn Rand', 'Mark Twain', 'Albert Einstein', 'Jane Austen', 'J.K. Rowling', 'Jane Austen', 'Jane Austen', 'C.S. Lewis', 'C.S. Lewis', 'Mark Twain', 'Mark Twain', 'C.S. Lewis', 'J.K. Rowling', 'Jimi Hendrix', 'J.M. Barrie', 'E.E. Cummings', 'Khaled Hosseini', 'Harper Lee', \"Madeleine L'Engle\", 'Mark Twain', 'Dr. Seuss', 'George R.R. Martin']\n"
     ]
    }
   ],
   "source": [
    "#while loop without predefined number of iterations\n",
    "#thus, we will use stopping condition\n",
    "all_authors=[]\n",
    "i=1\n",
    "while True: #run always, unless stopped by break\n",
    "    url = \"http://quotes.toscrape.com/page/{}/\".format(i)\n",
    "    current_page_authors = author_scraper(url)\n",
    "    if len(current_page_authors)!=0:\n",
    "        all_authors.extend(current_page_authors)\n",
    "        time.sleep(2)\n",
    "        i=i+1\n",
    "    else:\n",
    "        break\n",
    "print(all_authors)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Scrapy_notes.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
